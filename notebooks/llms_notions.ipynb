{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Neural Network Basics\n",
    "What is a Neural Network?\n",
    "Think of a neural network as a system that tries to imitate how the human brain processes information. The simplest form is a perceptron, which has:\n",
    "\n",
    "Inputs: Pieces of information (like numbers or words) coming in.\n",
    "Weights: Numbers that determine the importance of each input.\n",
    "Summation and Activation: The inputs are multiplied by their weights, added together, and passed through a function (called an activation function) to make a decision (like \"yes\" or \"no\").\n",
    "Example: If you wanted a neural network to decide if an email is spam, the inputs could be:\n",
    "\n",
    "Number of \"buy now\" phrases.\n",
    "Presence of suspicious links.\n",
    "Unusual sender address.\n",
    "The weights adjust to determine how important each factor is in deciding whether the email is spam.\n",
    "\n",
    "perceptron detailed explanation with examples :\n",
    "[Peceptron](https://www.w3schools.com/ai/ai_perceptrons.asp) \n",
    "\n",
    "articifial neuronal networks training and weight adjusting, visualization: \n",
    "[Artificial Neural Network visualization](https://playground.tensorflow.org/) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Complexity: Layers and Weights\n",
    "LLMs are much more complex. Instead of one perceptron, they have layers of interconnected perceptrons (nodes), each with their own weights.\n",
    "\n",
    "Weights are parameters the model adjusts during training to make better predictions.\n",
    "The process of finding the right weights is called training.\n",
    "Training with Errors:\n",
    "During training:\n",
    "\n",
    "The model makes a guess.\n",
    "It calculates how wrong it was using an error function.\n",
    "The model adjusts its weights to reduce future errors. This is called weights calibration.\n",
    "This process is repeated many times with a lot of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters in LLMs\n",
    "In a neural network:\n",
    "\n",
    "Parameters are the weights and biases the model learns during training.\n",
    "In LLMs, there can be billions or trillions of parameters because the model must understand and generate human language at an advanced level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Count\n",
    "The total number of parameters in a neural network is determined by:\n",
    "\n",
    "- The number of layers.\n",
    "\n",
    "- The number of neurons in each layer.\n",
    "\n",
    "- The connections between neurons in adjacent layers.\n",
    "\n",
    "- For example:\n",
    "  - In a simple feedforward network with one input layer (10 neurons), one hidden layer (20 neurons), and one output layer (5 neurons):\n",
    "  - Weights: 10×20 (connections from input to hidden) + 20×5\n",
    "                   (connections from hidden to output) = 250 weights.\n",
    "  - Biases: 20+5 = 25 biases.\n",
    "  - Total Parameters = 250+25 = 275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens and Embeddings\n",
    "LLMs work with tokens instead of raw text. A token is a small piece of text, like a word or even part of a word.\n",
    "\n",
    "The model converts these tokens into numbers using embeddings.\n",
    "Embeddings are like a map where similar words (like \"dog\" and \"puppy\") are placed closer together.\n",
    "This helps the model understand relationships between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Model?\n",
    "The \"model\" is essentially the trained neural network, with all its weights and parameters optimized for a specific task, like generating text, translating languages, or answering questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model/LLM  Temperature\n",
    "Temperature is an underlying factor that influences the model's output, when generating text, LLMs use temperature to control randomness:\n",
    "\n",
    "Low temperature (e.g., 0.2): The model is more focused and deterministic, repeating patterns it’s sure about.\n",
    "High temperature (e.g., 1.0): The model becomes more creative or random, exploring less common patterns.\n",
    "\n",
    "It determines whether the output will be more predictable or creative. A higher LLM temperature lets the model explore beyond its patterns. This LLM setting is best for brainstorming ideas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary with analogy, Imagine training a chef:\n",
    "\n",
    "The ingredients (tokens) are broken into parts and learned.\n",
    "Over time, the chef adjusts weights (importance of each ingredient) to make better recipes (text generation).\n",
    "The chef learns patterns like pairing flavors (embeddings).\n",
    "The chef can cook more structured meals (low temperature) or experiment creatively (high temperature).\n",
    "This chef, with all their experience, is your Large Language Model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
